"""
Custom App Inventory Transformer

This module provides functionality to transform CSV inventory files into
a standardized JSON format for custom applications.

The single app is set up to be used for multiple custom apps to make it easy
to share common code and maintainability. It is not a requirement to share the
transformer code between app but framework allows for that.

The transformer is based on three important parts

1. Base Class `CustomAppInventoryType1Transformer` that implements most common
utilities for the custom app. It implements utilities like csv readers, writers
validators etc. Important functions to be overriden are:
1.1 process_csv_row: This is callback invoked on every row.
1.2 constructor: for any set up for that app

2. Per Application Transformer Classes: These implement the logic for processing
every csv row and extract, user, role, assignments from it.

3. main function: It has the mapper for application name to Application Transformer class
Everytime a new application is created it needs to be updated.

4. tests: these are unit tests that can be used to validate application
transforming logic.

## Checklist for adding new Application

1. Take sample export of the application from real production data
2. Create a test data from the production data removing any PII
3. Add an Application Transformer class with following items
3.1 process_csv_row, create_user, create_role, create_role_assignment, create_permission
3.2 Add validators for the data specially assignment.
4. Add unit test for the Application
4.1 test the transform with sample data
5. Register the appplication in the `app_to_transformer_map`
6. Create Custom App Provider in Andromeda
7. Check custom app transfomer via `python3 custom_app_okta_bookmark_transformer.py --app_name=billing --inventory_file=billing_inventory.csv`
8. Upload the application and CSV to the UI
9. Optionally, use the sample app upload script to update the scripts
10. Validate the data in the Andromeda UI

"""

import argparse
import logging
import csv
import datetime
import json
from functools import partial
import traceback
from dataclasses import asdict, dataclass, field
from typing import Dict, List, Optional, Generator, Tuple, Any
from pathlib import Path
from enum import Enum, StrEnum

# Configure logging
logger = logging.getLogger(__name__)

# Constants
DEFAULT_BATCH_SIZE = 100
DEFAULT_OUTPUT_DIR = "/tmp/customapp_export"
DEFAULT_APP_NAME = "custom_app_sample"
ID_SEPARATOR = "|"

class UserStatus(Enum):
    """Represents a user status in the custom application inventory."""
    ENABLED = "ENABLED"
    DEACTIVATED = "DEACTIVATED"
    IDENTITY_STATUS_UNRESOLVED = "IDENTITY_STATUS_UNRESOLVED"
    SUSPENDED = "SUSPENDED"

class PrincipalType(Enum):
    """Represents a principal type in the custom application inventory."""
    HUMAN = "HUMAN"
    NHI = "NHI"
    GROUP = "GROUP"

class RoleType(Enum):
    """Represents a role type in the custom application inventory."""
    CUSTOM_APP_ROLE = "CUSTOM_APP_ROLE"
    CUSTOM_APP_USER_ROLE = "CUSTOM_APP_USER_ROLE"

class PermissionAccessLevel(Enum):
    """Represents a permission access level in the custom application inventory."""
    UNSPECIFIED = "UNSPECIFIED"
    LIST = "LIST"
    WRITE_TAG = "WRITE_TAG"
    DELETE_TAG = "DELETE_TAG"
    READ_METADATA = "READ_METADATA"
    READ_DATA = "READ_DATA"
    WRITE_METADATA = "WRITE_METADATA"
    CREATE = "CREATE"
    WRITE_DATA = "WRITE_DATA"
    DELETE_DATA = "DELETE_DATA"
    DELETE = "DELETE"
    PERMISSIONS_MANAGEMENT = "PERMISSIONS_MANAGEMENT"

class HrType(StrEnum):
    """Represents a HR type in the custom application inventory."""
    HR_TYPE_UNSPECIFIED = ""
    EMPLOYEE = "EMPLOYEE"
    CONTINGENT_WORKER = "CONTINGENT_WORKER"
    THIRD_PARTY = "THIRD_PARTY"

class NhiType(Enum):
    """Represents a service identity type in the custom application inventory."""
    CUSTOM_APP_NHI = "CUSTOM_APP_NHI"

@dataclass
class CustomAppUser:
    """Represents a user in the custom application inventory."""
    username: str
    name: str
    # if not provided, it will be generated by the transformer based on the username
    id: str
    status: Optional[str] = UserStatus.ENABLED.name
    # e.g., "employee", "contractor", "vendor", "customer", "partner", "other"
    hrType: Optional[str] = None

@dataclass
class CustomAppNhi:
    """Represents a user in the custom application inventory."""
    username: str
    name: str
    # if not provided, it will be generated by the transformer based on the username
    id: str
    type: Optional[str] = NhiType.CUSTOM_APP_NHI.name
    is_external_client: Optional[bool] = False

@dataclass
class CustomAppGroup:
    """Represents a user in the custom application inventory."""
    name: str
    # if not provided, it will be generated by the transformer based on the username
    id: str
    memberUserIds: List[str] = field(default_factory=list)
    memberSubgroupIds: List[str] = field(default_factory=list)

@dataclass
class CustomAppRole:
    """Represents a role in the custom application inventory."""
    name: str
    id: str
    type: Optional[str] = RoleType.CUSTOM_APP_ROLE.name
    # names of the permissions assigned to the role
    permissions: List[str] = field(default_factory=list)

@dataclass
class CustomAppRoleAssignment:
    """Represents a role assignment in the custom application inventory."""
    id: str
    principalId: str  # user, NHI, or group ID  # noqa: E501
    principalType: str  # noqa: E501
    roleId: str  # noqa: E501
    scopeId: Optional[str] = None  # noqa: E501

@dataclass
class CustomAppPermission:
    """Represents a permission in the custom application inventory."""
    name: str
    accessLevel: Optional[str] = None # e.g., "READ", "WRITE"  # noqa: E501
    serviceName: Optional[str] = None  # noqa: E501
    # noqa: E501

@dataclass
class CustomAppInventory:
    """Container for all custom application inventory data."""
    users: Dict[str, CustomAppUser] = field(default_factory=dict)
    roles: Dict[str, CustomAppRole] = field(default_factory=dict)
    assignments: Dict[str, CustomAppRoleAssignment] = field(default_factory=dict)
    permissions: Dict[str, CustomAppPermission] = field(default_factory=dict)
    groups: Dict[str, CustomAppGroup] = field(default_factory=dict)


class CustomAppInventoryType1Transformer:
    """
    Abstract class for custom app type1 inventory transformer.
    Implements all the common helper methods different custom apps
    """

    # Map of workload domains to hr types
    WORKLOAD_DOMAINS_HR_TYPE_MAP = None

    def __init__(self, app_name: str, inventory_file: str,
                 output_dir: str, has_extra_header_rows: bool=False,
                 field_names: Optional[List[str]]=None):
        self.app_name = app_name
        self.inventory_file = inventory_file
        self.inventory_type = 'CUSTOM_TYPE1_INVENTORY_CSV'
        self.output_dir = output_dir
        self.inventory = CustomAppInventory()
        self.has_extra_header_rows = has_extra_header_rows
        self.field_names = field_names

    def convert_to_andromeda_dict(self, obj: Any) -> Any:
        """
        Recursively convert dictionary keys from snake_case to camelCase.
        And removes empty values.
        Handles dictionaries, lists, and nested structures.
        Args:
            obj: Any object (dict, list, or primitive type)
        Returns:
            Object with snake_case keys converted to camelCase
        """
        if isinstance(obj, str):
            return obj
        if isinstance(obj, dict):
            # return key and values where value is not empty
            return {k:self.convert_to_andromeda_dict(v) for k, v in obj.items() if v}
        if isinstance(obj, list):
            return [self.convert_to_andromeda_dict(item) for item in obj if item]
        return obj

    def convert_snake_to_camel(self, snake_str: str) -> str:
        """Convert snake_case string to camelCase."""
        parts = snake_str.split('_')
        return parts[0] + ''.join(word.capitalize() for word in parts[1:])

    def csv_batch_reader(self, csv_file: str, batch_size: int=100) -> Generator[list, None, None]:
        """ Read CSV file in batches """
        with open(csv_file, 'r', encoding="utf-8", newline='', errors='ignore') as f:
            csv_reader = csv.DictReader(f)
            batch = []
            for row in csv_reader:
                batch.append(row)
                if len(batch) == batch_size:
                    yield batch
                    batch = []
            if batch:
                yield batch
    def csv_batch_reader_with_extra_header(
            self, csv_file: str, field_names: List[str],
            batch_size: int=100) -> Generator[list, None, None]:
        """ Read CSV file in batches """
        with open(csv_file, 'r', encoding="utf-8", newline='', errors='ignore') as f:
            csv_reader = csv.reader(f)
            batch = []
            for row in csv_reader:
                if not row:
                    # skip empty rows
                    continue
                if len(row) != len(field_names):
                    logger.info("Row %s has %d columns, expected %d",
                                row, len(row), len(field_names))
                # skip the first row
                if row[0] == 'Sr No':
                    continue
                # convert the row to a dictionary with the field names
                row_dict = dict(zip(field_names, row))
                batch.append(row_dict)
                if len(batch) == batch_size:
                    yield batch
                    batch = []
            if batch:
                yield batch


    def summarize(self) -> Dict[str, int]:
        """Generate summary statistics for inventory."""
        return {
            'users': len(self.inventory.users),
            'roles': len(self.inventory.roles),
            'assignments': len(self.inventory.assignments),
            'permissions': len(self.inventory.permissions),
            'groups': len(self.inventory.groups),
        }

    def transform_and_export(self) -> Tuple[CustomAppInventory, str]:
        """
        Transform the inventory csv into Andromeda Inventory and export it to a json file
        provided in the constructor
        Returns:
            Tuple[CustomAppInventory, str]: The inventory and the output file path
        """
        _, errors = self.transform()
        if errors:
            logger.error("Ignored errors found in inventory file %s\n %s",
                         len(errors), errors)
        # Create output directory if it doesn't exist
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)

        # Generate output filename
        timestamp = datetime.datetime.now().replace(
            microsecond=0, second=0, tzinfo=datetime.timezone.utc).isoformat()
        output_file = Path(f"{self.output_dir}/{self.app_name}-{timestamp}.json")

        # Log summary
        summary = self.summarize()
        logger.info("Summary of inventory file %s output to %s\n %s",
                    self.inventory_file, output_file, json.dumps(summary, indent=2))
        # Export to JSON
        try:
            # Convert to dictionary, camelize keys, and remove empty values
            #self.inventory_validation()
            inventory_dict = asdict(self.inventory)
            result_dict = self.convert_to_andromeda_dict(inventory_dict)
            with open(output_file, 'w', encoding="utf-8") as file:
                json.dump(result_dict, file, indent=2)
            # return full path of the output file
            return result_dict, str(output_file)
        except Exception as e:
            logger.error("Error writing output file %s: %s", output_file, e)
            logger.error("Stack trace: %s", traceback.format_exc())
            raise

    def transform(self) -> Tuple[CustomAppInventory, List[Dict[str, str]]]:
        """Transform Builder CSV inventory file."""
        errors = []
        try:
            csv_reader = (
                partial(self.csv_batch_reader_with_extra_header,
                        self.inventory_file, self.field_names)
                if self.has_extra_header_rows and self.field_names
                else partial(self.csv_batch_reader, self.inventory_file)
            )
            # read the csv file in batches
            for batch in csv_reader():
                for row in batch:
                    self.process_csv_row(row, errors)
        except Exception as e:
            logger.error("Error processing inventory file %s: %s", self.inventory_file, e)
            raise

        return self.inventory, errors

    def process_csv_row(self, row: Dict[str, str], errors: List[Dict[str, str]]):
        """Process a single CSV row and update inventory."""
        raise NotImplementedError("Subclass must implement this method")

    def inventory_validation(self) -> None:
        """Validate the inventory."""
        self._validate_users()
        self._validate_roles()
        self._validate_assignments()

    def _validate_users(self) -> None:
        """Validate user data in the inventory."""
        for user in self.inventory.users.values():
            if user.status not in UserStatus:
                logger.error("User %s has invalid status %s", user, user.status)
                raise ValueError(f"User {user} has invalid status {user.status}")

    def _validate_roles(self) -> None:
        """Validate role data in the inventory."""
        for role in self.inventory.roles.values():
            if role.type not in RoleType:
                logger.error("Role %s has invalid type %s", role, role.type)
                raise ValueError(f"Role {role} has invalid type {role.type}")
            self._validate_role_permissions(role)

    def _validate_role_permissions(self, role: CustomAppRole) -> None:
        """Validate that role permissions exist in the inventory."""
        for permission in role.permissions:
            if permission not in self.inventory.permissions:
                logger.error("Role %s has permission %s that is not defined", role, permission)
                raise ValueError(f"Role {role} has permission {permission} that is not defined")

    def _validate_assignments(self) -> None:
        """Validate assignment data in the inventory."""
        for assignment in self.inventory.assignments.values():
            self._validate_assignment_fields(assignment)
            self._validate_assignment_principal_type(assignment)
            self._validate_assignment_references(assignment)

    def _validate_assignment_fields(self, assignment: CustomAppRoleAssignment) -> None:
        """Validate mandatory fields for an assignment."""
        mandatory_fields = ['principalId', 'roleId']
        for f in mandatory_fields:
            if not getattr(assignment, f):
                logger.error("Assignment %s has no %s", assignment, f)
                raise ValueError(f"Assignment {assignment} has no {f}")

    def _validate_assignment_principal_type(self, assignment: CustomAppRoleAssignment) -> None:
        """Validate that assignment principal type is valid."""
        if assignment.principalType not in PrincipalType:
            logger.error("Assignment %s has invalid principalType %s",
                         assignment, assignment.principalType)
            raise ValueError(
                f"Assignment {assignment.id} has invalid principalType {assignment.principalType}")

    def _validate_assignment_references(self, assignment: CustomAppRoleAssignment) -> None:
        """Validate that assignment references exist in the inventory."""
        # Validate principal exists if it's a human
        if (assignment.principalType == PrincipalType.HUMAN.name and
            assignment.principalId not in self.inventory.users):
            logger.error("Assignment %s has invalid principalId %s",
                         assignment, assignment.principalId)
            raise ValueError(
                f"Assignment {assignment} has invalid principalId {assignment.principalId}")
        # Validate role exists
        if assignment.roleId not in self.inventory.roles:
            logger.error("Assignment %s has invalid roleId %s",
                         assignment, assignment.roleId)
            raise ValueError(f"Assignment {assignment} has invalid roleId {assignment.roleId}")

    def get_hr_type_from_username(self, username: str) -> HrType:
        """
        Get the hr type from the username.
        It checks against the workload domain map. If not found, it returns CONTINGENT_WORKER.
        """
        hr_type = HrType.HR_TYPE_UNSPECIFIED
        try:
            if self.WORKLOAD_DOMAINS_HR_TYPE_MAP:
                domain = username.split('@')[-1]
                hr_type = self.WORKLOAD_DOMAINS_HR_TYPE_MAP[domain]
        except KeyError as e:
            logger.debug("Error getting hrType for user %s: %s", username, e)
            hr_type = HrType.THIRD_PARTY
        except Exception as e:
            logger.error("Error getting hrType for user %s:, %s", username, e)
        return hr_type

class CustomAppOktaBookmarkTransformer(CustomAppInventoryType1Transformer):
    """
    Transforms Okta Bookmark CSV export files into standardized JSON format.

    Expected CSV columns:
      field_names
    """
    # Map user status based on user status
    last_user = None

    field_names = ['id', 'userName', 'scope', "externalId", "firstName", "lastName",
                   "syncState", "salesforceGroups", "samlRoles", "groupName"]

    def __init__(self, app_name: str, inventory_file: str, output_dir: str):
        super().__init__(app_name, inventory_file, output_dir)
        self.group_membership_map = {}

    def create_user(self, row: Dict[str, str], last_user: Optional[CustomAppUser] = None) -> Optional[CustomAppUser]:
        """Create a user object from CSV row data."""
        if not row.get('userName'):
            logger.error("Skipping row: userName not set in %s", row)
            raise ValueError(f"Skipping row: userName not set in {row}")

        username = row['userName'].strip()
        user_id = username
        first_name = row.get('firstName', '').strip()
        last_name = row.get('lastName', '').strip()
        name = f"{first_name} {last_name}".strip() if first_name or last_name else username
        status = UserStatus.ENABLED.name
        # Check if user is already present in the inventory
        if username in self.inventory.users:
            return self.inventory.users[username]

        user = CustomAppUser(
            id=user_id,
            username=username,
            name=name,
            status=status,
            #hrType=self.get_hr_type_from_username(username).value
        )
        logger.debug("Added user %s to inventory", user)
        self.inventory.users[username] = user
        return user


    def create_group(self, row: Dict[str, str]) -> Optional[CustomAppGroup]:
        """Create a group object from CSV row data."""
        scope = row.get('scope', '').strip()
        group_name = row.get('groupName', '').strip()

        if scope != "GROUP" or not group_name:
            logger.error("Skipping row: scope and group name are set in %s", row)
            return None
        group_id = group_name
        # Check if group is already present in the inventory
        if group_id in self.inventory.groups:
            return self.inventory.groups[group_id]

        group = CustomAppGroup(id=group_id, name=group_name)
        self.inventory.groups[group_id] = group
        logger.debug("Added group %s to inventory", group)
        return group

    def _create_role(self, role_name: str, user: Optional[CustomAppUser]) -> Optional[CustomAppRole]:
        role_name = role_name.strip()
        if role_name.lower() == 'none':
            return None
        if role_name:
            role_type = RoleType.CUSTOM_APP_ROLE.name
        elif user:
            role_type = RoleType.CUSTOM_APP_USER_ROLE.name
            role_name = f"{self.app_name}-{user.name}-role"
        else:
            raise ValueError(
                f"{self.app_name} user required when role name is null")
        # Check if role is already present in the inventory
        if role_name in self.inventory.roles:
            return self.inventory.roles[role_name]
        role = CustomAppRole(
            id=role_name,
            name=role_name,
            type=role_type,
        )
        logger.debug("Added role %s to inventory", role_name)
        self.inventory.roles[role_name] = role
        return role

    def create_roles(self, row: Dict[str, str],
        user: Optional[CustomAppUser]) -> List[CustomAppRole]:
        """Create a role object from CSV row data.
        Uses the Group name as the role name.
        """
        roles = []
        role_name = f"{self.app_name}-default-role"
        role = self._create_role(role_name, user)
        if role:
            roles.append(role)
        return roles

    def create_role_assignments(self, user: Optional[CustomAppUser],
            group: Optional[CustomAppGroup], roles: List[CustomAppRole],
            row: Dict[str, str]) -> List[CustomAppRoleAssignment]:
        """Create a role assignment object."""
        principal_id = group.id if group else user.id if user else ""
        principal_type = (PrincipalType.GROUP.name
                          if group else PrincipalType.HUMAN.name if user else "")
        assignments = []
        assert roles, f"Roles are not set for {self.app_name}"
        for role in roles:
            assignment_id = f"{self.app_name}{ID_SEPARATOR}{principal_type}{ID_SEPARATOR}{principal_id}{ID_SEPARATOR}{role.id}"
            # Check for assignment conflicts
            if assignment_id in self.inventory.assignments:
                if principal_type == PrincipalType.GROUP.name:
                    logger.warning("App: %s, Assignment already exists: %s %s", self.app_name,
                        assignment_id, self.inventory.assignments[assignment_id])
                assignments.append(self.inventory.assignments[assignment_id])
            else:
                assignment = CustomAppRoleAssignment(
                    id=assignment_id,
                    principalId=principal_id,
                    principalType=principal_type,
                    roleId=role.id,
                )
                logger.debug("Creating assignment %s for principal %s role %s", assignment.id,
                            principal_id, role.name)
                self.inventory.assignments[assignment.id] = assignment
                assignments.append(assignment)
        return assignments

    def _is_row_valid(self, row: Dict[str, str]) -> bool:
        """Check if the row needs to be processed."""
        # Row is valid if it has an email and group name
        user_name = row.get('userName', '').strip()
        group_name = row.get('groupName', '').strip()
        scope = row.get('scope', '').strip()
        return bool(user_name and (group_name or scope))

    def process_csv_row(self, row: Dict[str, str],
                         errors: List[Dict[str, str]]) -> None:
        """Process a single CSV row and update inventory.
        Returns:
            CustomAppUser: The last processed user object if the row is valid, otherwise None
        """
        #logger.debug("Processing row %s", row)
        if not self._is_row_valid(row):
            return
        try:
            # Create or update role
            roles = self.create_roles(row, None)
            if not roles:
                logger.debug("No roles found for app %s row %s", self.app_name, row)
                return
            # Create or update user
            user = self.create_user(row, self.last_user)
            # Create or update group
            group = self.create_group(row)
            # Create group binding
            if group and user:
                group_members = self.group_membership_map.get(group.id, set())
                if user.id not in group_members:
                    group_members.add(user.id)
                    self.group_membership_map[group.id] = group_members
                    group.memberUserIds.append(user.id)
            if (user or group) and roles:
                self.create_role_assignments(user, group, roles, row)
            self.last_user = user
            return
        except ValueError as e:
            logger.error("Error Processing row %s: %s", row, e)
            errors.append(row)
        except Exception as e:
            logger.error("Error processing row %s: %s", row, e)
            errors.append(row)
        return



def setup_logging() -> None:
    """Setup logging configuration."""
    logger.setLevel(logging.INFO)

    # Remove existing handlers to avoid duplicates
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)

    # Create console handler
    console_handler = logging.StreamHandler()
    formatter = logging.Formatter(
        '%(asctime)s:%(levelname)s:%(module)s:%(funcName)s:%(lineno)s: %(message)s'
    )
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)


def parse_arguments() -> argparse.Namespace:
    """Setup arguments for the script."""
    help_str = """
    This script is used by Andromeda to transform custom app type1 inventory csv into Andromeda Inventory
    Example:
        python3 custom_app_okta_bookmark_transformer.py --app_name=billing --inventory_file=billing_inventory.csv

    There is a registry of the application name to choose the transformer class if multiple present in
    a single file. Eg.
    app_to_transformer_map = {
        'custom_app_sample': CustomAppSampleTransformer,
    }
    """

    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawTextHelpFormatter,
        description=(help_str)
    )

    parser.add_argument(
        '--app_name', '-n', default='custom_app_sample',
        help='application name. Preffered to use the name used in custom application in Andromeda')

    parser.add_argument(
        '--inventory_file', '-i',
        help='inventory file name. Eg. inventory.csv')

    parser.add_argument(
        '--output_dir', '-o',
        help='output dir. Ouput is written to {output_dir}/{app_name}-{timestamp}.json',
        default='/tmp/customapp_export/')

    return parser.parse_args()


def main() -> None:
    """Main entry point for the script."""
    args = parse_arguments()
    setup_logging()

    app_to_transformer_map = {
        'OpsGenie': CustomAppOktaBookmarkTransformer,
        'Torq': CustomAppOktaBookmarkTransformer,
        'ServiceNow': CustomAppOktaBookmarkTransformer,
        'Secure Access Cloud (Luminate)': CustomAppOktaBookmarkTransformer,
    }
    try:
        # Find the transformer class based on the app name
        # TODO: change this to actually fail if the transformer class is not found
        # need product change
        transformer_class = app_to_transformer_map.get(
            args.app_name.strip(), CustomAppOktaBookmarkTransformer)

        transformer_class.WORKLOAD_DOMAINS_HR_TYPE_MAP = {
            'deepwatch.com': HrType.HR_TYPE_UNSPECIFIED,
        }
        # Create the transformer instance
        transformer = transformer_class(
            app_name=args.app_name.strip(),
            inventory_file=args.inventory_file.strip(),
            output_dir=args.output_dir.strip())

        # Transform and export the inventory
        _, output_file = transformer.transform_and_export()
        logger.info("Transformation completed for app %s successfully, output file: %s", args.app_name, output_file)

    except Exception as e:
        logger.error("Transformation failed: {%s}", e)
        logger.error("Stack trace: %s", traceback.format_exc())
        raise


if __name__ == '__main__':
    main()
